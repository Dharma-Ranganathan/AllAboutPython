{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharma-Ranganathan/AllAboutPython/blob/main/Data_Preprocessing_%26_Standardization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING AND DATA STANDARDIZATION FOR MAKING ABSOLUTE PREDICTIONS"
      ],
      "metadata": {
        "id": "2OUl8RaOP5GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING RELIABLE LIBRARIES\n",
        "import pandas as pd\n",
        "\n",
        "# IMPORTING SKLEARN LIBRARIES\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# creating df using pandas\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# checking dataset\n",
        "cancer_df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
        "\n",
        "# data pre-processing\n",
        "\n",
        "# checking if features contain null values\n",
        "cancer_df.isnull().sum()\n",
        "\n",
        "# data standardizing\n",
        "\n",
        "# training and testing the data points\n",
        "x = cancer_df\n",
        "y = cancer.target\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=3)\n",
        "\n",
        "# print(x_train.shape, x_test.shape, x.shape)\n",
        "\n",
        "# checking range or difference in data points using standard deviation\n",
        "\n",
        "# print(x.std()) # - results in higher variance of each data points which leads to overfitting\n",
        "\n",
        "# standard-scaler for diminishing higher variance and formating common range to each data points\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train_standardized = scaler.transform(x_train)\n",
        "\n",
        "# checking current range or difference in trained standardized data points\n",
        "\n",
        "\"\"\"\n",
        "NOTE :\n",
        "1. standard deviation - 1.0 - absolute predictions\n",
        "2. standard deviation > 1.0 or < 1.0 - predictions will results as good in training time , but over the time , prediction complexes will occur\n",
        "\"\"\"\n",
        "# print(x_train_standardized.std()) # - results in 1.0 , which leads to have absolute predictions over time and formated range commonly\n",
        "\n",
        "# standardizing x_test data points also\n",
        "\n",
        "# before standardizing\n",
        "\n",
        "# print(\"before: \")\n",
        "# print(x_test.std())\n",
        "\n",
        "# after standardizing\n",
        "\n",
        "x_test_standardized = scaler.transform(x_test)\n",
        "\n",
        "# print(x_test_standardized.std()) # - results in nearest to 1.0 as same as x_train - absolute predictions will occur"
      ],
      "metadata": {
        "id": "7idc5JxCQCjN"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}
